{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linglong/data/linglong/.conda/envs/acc/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "import numpy as np\n",
    "import literature\n",
    "\n",
    "R = sparse.load_npz(\"data/thrm_vertex_matrix.npz\")\n",
    "mats = np.array(open(\"data/thrm_mats.txt\", \"r\").read().splitlines())\n",
    "props = [\"thermoelectric\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yrs = np.loadtxt('data/thrm_years.txt')\n",
    "R = R[(yrs>=1996)*(yrs<=2000),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = literature.hypergraph(R, mats, props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 20                 # length of the walk\n",
    "size = 1                    # number of the walk\n",
    "prop_ind = R.shape[1]-1     # column index of the property as the starting node "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['thermoelectric CeGeNi a_886058 a_885358 Al10Ce10NiPd9 a_886058 a_885610 thermoelectric a_425231 a_524526 thermoelectric a_1710042 thermoelectric a_815535 KO5PTi K2O Na2O GeO2 a_99281 GeO2'],\n",
       " ['50739 50739 50737 50729 50729 52319 50739 9151 9151 9151 83553 83553 18658 18633 49949 19121 36848 646 646'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.random_walk(length, size, start_inds=prop_ind, rand_seed=0)    # uniform sampling\n",
    "\n",
    "# resulting in the following output: \n",
    "# (the first array is the sequence of selected nodes; the second array is the selected papers along the walk):\n",
    "# ---------------------\n",
    "# (['thermoelectric a_1244326 a_1084770 a_1085357 CoCrFeMnNi a_281555 a_1076970 CSi a_10764 Al2O3\n",
    "# K2O a_1672448 CaF2 a_460834 BaF2 a_638548 a_1287239 a_955446 a_955445 a_955447'],\n",
    "#  ['962469 1191497 746280 1191497 1421491 734403 1115449 132804 46832 1194889 1400463 1400463 23\n",
    "# 2314 232314 894012 1035899 1035899 615755 1075096'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"rw_seqs.txt\", \"w\") as file:\n",
    "    for i in range(100):\n",
    "        rw_seqs = h.random_walk(length, size, start_inds=prop_ind, alpha=2, rand_seed=i)[0][0]    # non-uniform sampling (alpha=1)\n",
    "        file.write(rw_seqs+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6759"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils \n",
    "seqs = open(\"rw_seqs.txt\").read().splitlines()                              # reading the sequences\n",
    "seqs_noauthors = utils.remove_authors_from_RW(seqs)                         # removing the author nodes\n",
    "open(\"rw_seqs_noauthors.txt\", \"w\").write(\"\\n\".join(seqs_noauthors)+\"\\n\")    # saving the pruned sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 15:15:20,950 : INFO : Parsing lines (sentences) in: rw_seqs_noauthors.txt: \n",
      "2023-11-07 15:15:20,951 : INFO : Parameters for parsing phrases are as follows:\n",
      "2023-11-07 15:15:20,951 : INFO : \tdepth: 2\n",
      "2023-11-07 15:15:20,952 : INFO : \tphrase_min_count: 10\n",
      "2023-11-07 15:15:20,952 : INFO : \tphrase_threshold: 15\n",
      "2023-11-07 15:15:20,953 : INFO : collecting all words and their counts\n",
      "2023-11-07 15:15:20,953 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2023-11-07 15:15:20,955 : INFO : collected 1015 word types from a corpus of 842 words (unigram + bigrams) and 92 sentences\n",
      "2023-11-07 15:15:20,956 : INFO : using 1015 counts as vocab in Phrases<0 vocab, min_count=10, threshold=15, max_vocab_size=40000000>\n",
      "2023-11-07 15:15:20,956 : INFO : source_vocab length 1015\n",
      "2023-11-07 15:15:20,962 : INFO : Phraser built with 0 phrasegrams\n",
      "0it [00:00, ?it/s]\n",
      "2023-11-07 15:15:20,967 : INFO : collecting all words and their counts\n",
      "2023-11-07 15:15:20,968 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2023-11-07 15:15:20,972 : INFO : collected 1015 word types from a corpus of 842 words (unigram + bigrams) and 92 sentences\n",
      "2023-11-07 15:15:20,972 : INFO : using 1015 counts as vocab in Phrases<0 vocab, min_count=10, threshold=15, max_vocab_size=40000000>\n",
      "2023-11-07 15:15:20,973 : INFO : source_vocab length 1015\n",
      "2023-11-07 15:15:20,983 : INFO : Phraser built with 0 phrasegrams\n",
      "0it [00:00, ?it/s]\n",
      "2023-11-07 15:15:20,987 : INFO : collecting all words and their counts\n",
      "2023-11-07 15:15:20,988 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-11-07 15:15:20,993 : INFO : collected 380 word types from a corpus of 842 raw words and 92 sentences\n",
      "2023-11-07 15:15:20,994 : INFO : Loading a fresh vocabulary\n",
      "2023-11-07 15:15:20,995 : INFO : effective_min_count=5 retains 20 unique words (5% of original 380, drops 360)\n",
      "2023-11-07 15:15:20,995 : INFO : effective_min_count=5 leaves 281 word corpus (33% of original 842, drops 561)\n",
      "2023-11-07 15:15:20,996 : INFO : deleting the raw counts dictionary of 380 items\n",
      "2023-11-07 15:15:20,997 : INFO : sample=0.0001 downsamples 20 most-common words\n",
      "2023-11-07 15:15:20,997 : INFO : downsampling leaves estimated 11 word corpus (4.0% of prior 281)\n",
      "2023-11-07 15:15:20,998 : INFO : constructing a huffman tree from 20 words\n",
      "2023-11-07 15:15:20,999 : INFO : built huffman tree with maximum node depth 6\n",
      "2023-11-07 15:15:21,000 : INFO : estimated required memory for 20 words and 200 dimensions: 62000 bytes\n",
      "2023-11-07 15:15:21,000 : INFO : resetting layer weights\n",
      "2023-11-07 15:15:21,006 : INFO : training model with 20 workers on 20 vocabulary and 200 features, using sg=1 hs=1 sample=0.0001 negative=15 window=8\n",
      "2023-11-07 15:15:21,007 : INFO : training on a 0 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2023-11-07 15:15:21,008 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2023-11-07 15:15:21,009 : INFO : Training the model using the following parameters:\n",
      "2023-11-07 15:15:21,009 : INFO : \tphrase_min_count: 10\n",
      "2023-11-07 15:15:21,010 : INFO : \tsize: 200\n",
      "2023-11-07 15:15:21,010 : INFO : \twindow: 8\n",
      "2023-11-07 15:15:21,011 : INFO : \tmin_count: 5\n",
      "2023-11-07 15:15:21,011 : INFO : \tsg: True\n",
      "2023-11-07 15:15:21,012 : INFO : \ths: True\n",
      "2023-11-07 15:15:21,013 : INFO : \tworkers: 20\n",
      "2023-11-07 15:15:21,016 : INFO : \tnegative: 15\n",
      "2023-11-07 15:15:21,017 : INFO : \tstart_alpha: 0.001\n",
      "2023-11-07 15:15:21,017 : INFO : \tend_alpha: 0.0001\n",
      "2023-11-07 15:15:21,018 : INFO : \tsubsample: 0.0001\n",
      "2023-11-07 15:15:21,018 : INFO : \tbatch: 5000\n",
      "2023-11-07 15:15:21,019 : INFO : \tepochs: 5\n",
      "2023-11-07 15:15:21,020 : INFO : The model will be saved in None\n",
      "2023-11-07 15:15:21,020 : INFO : training model with 20 workers on 20 vocabulary and 200 features, using sg=1 hs=1 sample=0.0001 negative=15 window=8\n",
      "2023-11-07 15:15:21,035 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2023-11-07 15:15:21,036 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2023-11-07 15:15:21,037 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2023-11-07 15:15:21,038 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2023-11-07 15:15:21,038 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2023-11-07 15:15:21,039 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2023-11-07 15:15:21,040 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2023-11-07 15:15:21,041 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2023-11-07 15:15:21,042 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2023-11-07 15:15:21,043 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2023-11-07 15:15:21,043 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2023-11-07 15:15:21,044 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2023-11-07 15:15:21,045 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2023-11-07 15:15:21,046 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2023-11-07 15:15:21,047 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2023-11-07 15:15:21,047 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2023-11-07 15:15:21,048 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2023-11-07 15:15:21,048 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-11-07 15:15:21,049 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-11-07 15:15:21,049 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-11-07 15:15:21,050 : INFO : EPOCH - 1 : training on 842 raw words (12 effective words) took 0.0s, 549 effective words/s\n",
      "2023-11-07 15:15:21,050 : INFO : 1 Epoch(s) done. Loss: 0.0, LR: 0.001\n",
      "2023-11-07 15:15:21,068 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2023-11-07 15:15:21,069 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2023-11-07 15:15:21,070 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2023-11-07 15:15:21,071 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2023-11-07 15:15:21,072 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2023-11-07 15:15:21,072 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2023-11-07 15:15:21,073 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2023-11-07 15:15:21,074 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2023-11-07 15:15:21,075 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2023-11-07 15:15:21,075 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2023-11-07 15:15:21,076 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2023-11-07 15:15:21,077 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2023-11-07 15:15:21,077 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2023-11-07 15:15:21,078 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2023-11-07 15:15:21,079 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2023-11-07 15:15:21,079 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2023-11-07 15:15:21,080 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2023-11-07 15:15:21,081 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-11-07 15:15:21,081 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-11-07 15:15:21,082 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-11-07 15:15:21,082 : INFO : EPOCH - 2 : training on 842 raw words (16 effective words) took 0.0s, 657 effective words/s\n",
      "2023-11-07 15:15:21,083 : INFO : 2 Epoch(s) done. Loss: 0.0, LR: 0.001\n",
      "2023-11-07 15:15:21,104 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2023-11-07 15:15:21,105 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2023-11-07 15:15:21,106 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2023-11-07 15:15:21,107 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2023-11-07 15:15:21,108 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2023-11-07 15:15:21,109 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2023-11-07 15:15:21,110 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2023-11-07 15:15:21,111 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2023-11-07 15:15:21,111 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2023-11-07 15:15:21,112 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2023-11-07 15:15:21,113 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2023-11-07 15:15:21,114 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2023-11-07 15:15:21,115 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2023-11-07 15:15:21,116 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2023-11-07 15:15:21,116 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2023-11-07 15:15:21,117 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2023-11-07 15:15:21,117 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2023-11-07 15:15:21,118 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-11-07 15:15:21,118 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-11-07 15:15:21,119 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-11-07 15:15:21,119 : INFO : EPOCH - 3 : training on 842 raw words (13 effective words) took 0.0s, 484 effective words/s\n",
      "2023-11-07 15:15:21,120 : INFO : 3 Epoch(s) done. Loss: 58.624534606933594, LR: 0.001\n",
      "2023-11-07 15:15:21,137 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2023-11-07 15:15:21,138 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2023-11-07 15:15:21,139 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2023-11-07 15:15:21,140 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2023-11-07 15:15:21,140 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2023-11-07 15:15:21,141 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2023-11-07 15:15:21,142 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2023-11-07 15:15:21,143 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2023-11-07 15:15:21,143 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2023-11-07 15:15:21,144 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2023-11-07 15:15:21,145 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2023-11-07 15:15:21,146 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2023-11-07 15:15:21,146 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2023-11-07 15:15:21,147 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2023-11-07 15:15:21,147 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2023-11-07 15:15:21,148 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2023-11-07 15:15:21,148 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2023-11-07 15:15:21,149 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-11-07 15:15:21,149 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-11-07 15:15:21,150 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-11-07 15:15:21,150 : INFO : EPOCH - 4 : training on 842 raw words (11 effective words) took 0.0s, 478 effective words/s\n",
      "2023-11-07 15:15:21,151 : INFO : 4 Epoch(s) done. Loss: 29.71660614013672, LR: 0.001\n",
      "2023-11-07 15:15:21,172 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2023-11-07 15:15:21,175 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2023-11-07 15:15:21,176 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2023-11-07 15:15:21,177 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2023-11-07 15:15:21,179 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2023-11-07 15:15:21,179 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2023-11-07 15:15:21,180 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2023-11-07 15:15:21,181 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2023-11-07 15:15:21,181 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2023-11-07 15:15:21,182 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2023-11-07 15:15:21,182 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2023-11-07 15:15:21,183 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2023-11-07 15:15:21,183 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2023-11-07 15:15:21,184 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2023-11-07 15:15:21,184 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2023-11-07 15:15:21,184 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2023-11-07 15:15:21,185 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2023-11-07 15:15:21,185 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-11-07 15:15:21,186 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-11-07 15:15:21,186 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-11-07 15:15:21,187 : INFO : EPOCH - 5 : training on 842 raw words (12 effective words) took 0.0s, 460 effective words/s\n",
      "2023-11-07 15:15:21,187 : INFO : 5 Epoch(s) done. Loss: 55.20796203613281, LR: 0.001\n",
      "2023-11-07 15:15:21,190 : INFO : training on a 4210 raw words (64 effective words) took 0.2s, 379 effective words/s\n",
      "2023-11-07 15:15:21,190 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "seqs_noauthor_path = \"rw_seqs_noauthors.txt\"\n",
    "\n",
    "import embedding\n",
    "embed = embedding.dww2v(seqs_noauthor_path, workers=20)     # initiating deepwalk model with a different value for parameter workers\n",
    "embed.build_model()\n",
    "embed.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims,_,reordered_mats = embed.similarities(['thermoelectric'], mats, return_nan=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_R = sparse.load_npz(\"data/thrm_vertex_matrix.npz\")\n",
    "subgraph_R = full_R[yrs<=2000]\n",
    "studied_mats = mats[np.asarray(np.sum(subgraph_R[:,h.nA:-1].multiply(subgraph_R[:,-1]), axis=0)>0)[0,:]]\n",
    "candidate_mats = mats[~np.isin(mats,studied_mats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['F6S', 'H2O', 'O2Si', ..., 'Si12Zr13', 'Si29Zr21', 'AgGe4SbTe6'],\n",
       "      dtype='<U48')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['F6S', 'O4SiTi', 'GeO2', ..., 'Si12Zr13', 'Si29Zr21', 'AgGe4SbTe6'],\n",
       "      dtype='<U48')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_mats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.33034265, -0.01158052,  0.02781176]]),\n",
       " array(['thermoelectric'], dtype='<U14'),\n",
       " array(['CsOV', 'GaN', 'O4RuSr2'], dtype='<U7'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed.similarities(['thermoelectric'], candidate_mats, return_nan=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims,_,reordered_mats = embed.similarities(['thermoelectric'], candidate_mats, return_nan=False)\n",
    "\n",
    "# reporting 50 materials with highest likelihood of being thermoelectric\n",
    "preds = reordered_mats[np.argsort(-sims[0,:])][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.33333333, 0.33333333, 0.33333333,\n",
       "       0.33333333, 0.66666667, 0.66666667, 0.66666667, 0.66666667,\n",
       "       0.66666667, 0.66666667, 0.66666667, 0.66666667, 0.66666667,\n",
       "       0.66666667, 0.66666667, 0.66666667])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "gt_discs = json.load(open(\"data/thrm_groundtruth_discs.json\",\"r\")) \n",
    "yearwise_precs = [np.isin(preds,gt_discs[str(x)]).sum()/len(preds) for x in range(2001,2019)]\n",
    "np.cumsum(yearwise_precs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
